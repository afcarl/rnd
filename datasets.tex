\section{Datasets and Benchmarks in Action Recognition}
\label{chap:datasets}

``From a practical standpoint, there are currently no video classification benchmarks that match the scale and variety of existing image datasets because videos are significantly more difficult to collect, annotate and store.'' cite large-scale image classification

``In particular, commonly used datasets (KTH, Weizmann, UCF Sports, IXMAS, Hollywood 2, UCF-50) only contain up to few thousand clips and up to few dozen classes.
Even the largest available datasets such as CCV (9,317 videos and 20 classes) and the recently introduced UCF-101[22] (13,320 videos and 101 classes) are still dwarfed by available image datasets in the number of instances and their variety [7].'' cite large-scale image classification

``In [4], Gao et al. presented a comprehensive study on the influence of the evaluation protocol on the final results. It was shown that the use of different experimental configurations can lead to performance differences up to 9\%.''
``Action recognition methods are usually directly compared although they use different testing protocols or/and datasets (KTH1 or KTH2), which distorts the conclusions.''
cite sequential deep learning for human action recognition.

\subsection{Review of Datasets for Human Action Classification}
Review of the most important currently existing datasets, focus on newest ones (since 2013)

Reference dataset survey paper.

\subsection{Alternative Benchmarks for Action Recognition Algorithms}

\subsection{Data Augmentation}

refer to Imagenet classification with deep convolutional neural networks.

\subsection{Inter-Dataset Approaches}

\subsubsection{Multi-task learning}

\subsubsection{Transfer learning}

See Karparthy 'Large-scale video classification with convolutional neural networks' 2014

A. S. Razavian, H. Azizpour, J. Sullivan, and S. Carls-
son. CNN features off-the-shelf: an astounding baseline for
recognition

\subsubsection{Unsupervised pre-training}
