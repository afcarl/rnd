% arara: pdflatex
% arara: biber
% arara: pdflatex
% arara: pdflatex
%\documentclass[12pt, a4paper, parskip=half, listof=totoc, bibliography = totoc]{scrartcl}
\documentclass[a4paper, 11pt, listof=totoc, bibliography=totoc]{scrartcl}

\usepackage[english]{babel} 
\usepackage[T1]{fontenc} %latex Ausgabefont
\usepackage[utf8]{inputenc} %Eingabecodierung
%\usepackage{lmodern}

% bibliography
\usepackage[pdfborderstyle={/S/U/W 0}]{hyperref}
\usepackage[hyperref = true, backend=biber, style=numeric, sorting = none]{biblatex}
\addbibresource{bibliography.bib}
\addbibresource{bibliography_related.bib}
\AtEveryBibitem{\clearfield{note}}
\AtEveryBibitem{\clearfield{timestamp}}
\AtEveryBibitem{\clearfield{urldate}}
\AtEveryBibitem{\clearfield{doi}}
\AtEveryBibitem{\clearfield{isbn}}
\AtEveryBibitem{\clearfield{series}}
\AtEveryBibitem{\clearfield{volume}}
\AtEveryBibitem{\clearfield{number}}
\AtEveryBibitem{\clearfield{pages}}
\AtEveryBibitem{\clearfield{issue}}
\AtEveryBibitem{\clearfield{publisher}}
\DeclareSourcemap{
  \maps[datatype=bibtex, overwrite]{
    \map{
%      \step[fieldset=language, null]
      \step[fieldset=urldate, null]
    }
  }
}
%---Packages---
\usepackage{graphicx}
\usepackage{float}
\usepackage[format = hang, figurename = {Figure}, tablename = {Table}, font = small, labelfont= it, position = below]{caption}
\usepackage[format = hang, indention = 0.0cm]{subcaption}
\usepackage{url}
\usepackage{tabularx}
\usepackage{textcomp}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{wrapfig}
\usepackage{enumitem}
\usepackage{parskip}
\usepackage{setspace}


\begin{document}
\thispagestyle{empty}
\begin{center}
\large
\textbf{Research \& Development Report} \\
Master Autonomous Systems \\
University of Applied Sciences Bonn-Rhein-Sieg \\
\LARGE

\vspace{1cm}

\vspace{-0.75\baselineskip}\rule{\linewidth}{1.5pt}
\textbf{Evaluation of current Approaches for Situation-Awareness in Autonomous Systems from Action Recognition in Video Data} \\
\vspace{-0.25\baselineskip}\rule{\linewidth}{1.5pt}

\vspace{1cm}

\normalsize
\textit{Author:}\\
Maximilian Schöbel\\
Mat. Nr. 9027059
\bigskip

\textit{Advisors:}\\
Prof. Dr. Erwin Prassler\\
Prof. Dr. Paul G. Plöger\\
\bigskip

January 12th, 2017

\vfill

\textbf{Abstract}
\end{center}
\small
Situation awareness is an abstract concept, which includes several independent manifestations and sensory inputs.
An important aspect of situation awareness is the knowledge of actions, that are performed by persons in the vicinity of an agent, to derive a suitable policy for the agent's own future actions.
This report investigates vision-based human action recognition from video data as a key step towards the understanding of scenes by autonomous (robotic) systems.
Recognition of actions furthermore enables applications in surveillance systems, patient monitoring, human-computer interfaces, assisted living environments and AI.
So far, computer vision research produced two main approach classes of machine learning based algorithms for classifying actions in video-data:
Either using arbitrary classification techniques on top of hand-crafted feature extractors or end-to-end trainable deep learning architectures.
This report provides a detailed review of current deep learning approaches for video-based action recognition in addition to a comparison with conventional hand-crafted feature approaches.
Furthermore, publicly available video datasets are reviewed, since the availability of labeled large-scale datasets is a big challenge in deep learning.
Even very recent video-datasets do not match the size of existing image datasets.
Results indicate, that deep learning techniques are competitive but not yet able to significantly outperform conventional hand-crafted feature methods in video-based action recognition.

\newpage

\thispagestyle{empty}
\hfill

\newpage

\thispagestyle{empty}
\footnotesize
\tableofcontents
\normalsize

\newpage

\section*{Statement of Originality}

This is to certify that the content of this report is my own work and that all sources have been acknowledged.


Date:


Signature: 
\newpage
\hfill
\newpage

\include{introduction}
\include{conventional}
\include{deep}
\include{datasets}
\include{evaluation}

\newpage

\printbibliography

\end{document}
