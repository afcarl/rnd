Abstract:
We investigate human action recognition from video data as a key step towards the autonomous understanding of scenes in the environment of an autonomous (robotic) system.
Describe current approaches.
Biggest problems: Availability of data
How to overcome: Unsupervised learning


\section{Introduction}
META: Brief but concise review of the first two "W"s.

The operation of autonomous mobile systems in public, uncontrolled environments is despite active research still a difficult task.

Humans are perfectly able to act and move in unknown, crowded environments and even react successfully to new situations because they are aware of their surroundings.

An important part of Situation Awareness is the knowledge of what actions are currently performed by persons in the vicinity of an agent.
This knowledge enables the agent to derive a suitable policy for its own future actions.

Actions of interest are single-person actions, person-person interactions, person-object interactions and group activities.

Enabling situation-awareness in autonomous systems is an important goal, which has an impact on other problems in autonomous systems.

Possible applications:\\
Pedestrian movement predicition in robotics,\\
Risk and danger evaluation through video surveillance in public environements,\\
surveillance of children or the elderly in assisted living environments,\\
patient monitoring in hospitals,\\
video retrieval (content-based video indexing),\\
human-computer interaction.\\

Requirement: Automated recognition of high-level actions.

Situation awareness is an abstract concept, which includes lots of independent manifestations and involves multiple sensory inputs.

This work focuses on approaches that process time-sequential video data, because video-cameras represent a cost-effective and widely used technology in many existing systems.

Motivation for using videos: Promising results in classfication tasks from images.
Video adds another (temporal) dimension, which conveys a lot of information that can be accessed for classification as well.
Video provides natural data augmentation cite:simnoyan two-stream paper (??)

\subsection{Situation Awareness from video data}

META: General Definition of Situation Awareness in the context of autonomous systems.

Placement of Action Recognition among other vision-based methods, i.e.

Action Prediction, Anomaly Detection, Event and Action Detection, Person/Pedestrian Detection, Gesture Recognition.o

Abnormal event detection O. Boiman and M. Irani. Detecting irregularities in images and in video. IJCV, 2007

Activity understanding ``activity forecasting''

Definitions of the above methods.

Simple case: Video contains the performance of a single human action which needs to be classified into one of several preknown classses.

General real-world case: System operates on a video stream and needs to perform continuous recognition of human actions, including detection of beginning and endings times of containing acions.

General Processing Pipeline for Action Recognition: Person Detection -> Tracking -> Action Detection -> Segmentation -> Action recognition.

Action Recognition: A part of Computer Vision research, it's goal is to automatically analyze human actions/actitvities from video-data.

Other sensory input than video possible 

\subsection{The Action Recognition Problem}
Action Recognition is a classification-task.

Difference to face/gate recognition: Generalize over person characteristics.

Intra- and inter-class variances.

Background and recording settings.

Temporal variations.

Obtaining and labeling training data.

Main task of action recognition research: Overcome these challenges and built systems, that recognize actions robustly, even when performed by different persons in differently lighted environments at different speeds.

Main components: (i) A discriminative architecture that is able to recognise the general characteristics of different action classes while ignoring personal characteristics of different performers.
(ii) Large datasets that provide this information by containing many different examples for each action class.

\subsection{Survey Papers in Action Recognition (Related work)}

Review of most important/recent review papers in Action Recognition with traditional and Deep Learning approaches.

\subsubsection{A survey on vision-based human action recognition, Ronald Poppe (2010)}

\textbf{Definition of action:} Uses the hierarchical classification of human motion in action primitives, actions and activities as given in Moeslund et al. (cite ??)

Action primitives are atomic movements at the limb-level.

Actions are possibly cyclic whole body movements and consist of multiple action primitives.

Activities consist of multiple actions whose subsequent execution make the movement interpretable.

Example: Action primitives: Left/right leg forward -> Action: Starting, Running, Jumping -> Activity: Jumping hurdles.

\textbf{Scope:} Gives a very good classification of conventional methods in human action recognition.

The discussion is split according to video representations and classification methods.

Challenges of the domain are described very well.

\textbf{Deficits:} No Deep Learning methods are discussed.

Datasets and benchmarks are only discussed briefly.

\subsubsection{Human Activity Analysis: A Review -- Aggarwal and Ryoo (2011)}

Gives an approach-based taxonomy.

\subsubsection{A survey on vision-based methods for action representation, segmentation and recognition -- Weinland et al. (2011)}

\subsubsection{A survey of video datasets for human action and activity recognition -- Chaquet et al. (2013)}

\subsubsection{A review of unsupervised feature learning and deep learning for time-series modeling -- LÃ¤ngkvist et al. (2014)}

\subsubsection{Going Deeper into Action Recognition: A survey -- Herath et al. (2016)}

\textbf{Definition of action:} 

\subsection{Important aspects of Action Recognition Approaches}
video representations, i.e.\ how to apply fixed length model to variable length videos.
